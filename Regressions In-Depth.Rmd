---
title: "Regressions In-Depth"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(tidyverse)
library(here)
library(stargazer)
library(ggplot2)
#library(sjPlot)
library(interactions)
library(car)
library(olsrr)
library(corrplot)

#### Load data ####
df_1 <- readRDS(here("data", "T2T Data for Jans et al.rds"))



####  Prepare Data  ####
df_2 <- df_1 %>%
  
  # Adding a column for CDI mean
  mutate(cdi_mean = rowMeans(select(.,contains("cdi")), na.rm = FALSE)) %>%
  
  # Selecting variables
  select(yb_lsmh_id,
         # Demographic variables
         pb_childgender, pb_income, pb_childethnicity,
         # Variables for analysis
         yb_permanence, yb_cause_brain, yb_cause_env, yb_change_brain, yb_change_env, cdi_mean) %>%
  
  # Removing rows containing NA
  filter(complete.cases(.)) %>%
  
  # Standardize numeric variables
  mutate(across(c(yb_permanence, yb_cause_brain, yb_cause_env, yb_change_brain, yb_change_env, cdi_mean), 
                scale,
                .names = "{col}_scaled"))
```

# Brain Regressions

```{r, results = "asis", echo = F}
model1 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_brain_scaled)
model2 <- lm(data = df_2, yb_permanence_scaled ~ yb_change_brain_scaled)
model3 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_brain_scaled + yb_change_brain_scaled) 
model4 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_brain_scaled + yb_change_brain_scaled + yb_cause_brain_scaled*yb_change_brain_scaled)
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_brain_scaled + yb_change_brain_scaled + yb_cause_brain_scaled*yb_change_brain_scaled + cdi_mean_scaled)

stargazer(model1, model2, model3, model4, model5, type = "html")

#plot_model(model5, type="pred", terms= "yb_cause_brain_scaled")
#plot_model(model5, type="pred", terms= "yb_change_brain_scaled")
interact_plot(model5, pred= yb_cause_brain_scaled, modx= yb_change_brain_scaled, plot.points = FALSE, interval = TRUE, main.title = "Brain Interaction Controlling for CDI")
```

The first regression indicates a weak, but significant, relationship between `cause_brain` _(believing depression is caused by one's brain)_ and `permanence` _(believing depression is permanent)_. Specifically, a standard deviation increase in `cause_brain` is associated with a .22 standard deviation increase in `permanence`. Looking at `change_brainv` _(believing one's brain can change to make depression less permanent)_, we see a similar but inverse pattern. 

When we include both `cause_brain` and `change_brain` in the same model, not only do both remain significant, but their coefficients increase; it appears that both (a) `cause_brain` is a stronger predictor of `permanence` when controlling for `change_brain`, and (b) `change_brain` is a stronger predictor of `permanence` when controlling for `cause_brain`. Also look at the R^2; the model with both predictors accounts for 16% of the variance in `permanence`, while on their own the two predictors account for 5% and 6%. The combined model is more powerful than the sum of its parts, which is interesting to me.

Now, to the interaction. It isn't significant. Basically, the data don't indicate that when people believe their brain can change to make depression less permanent, the relationship between believing the brain causes depression and the perceived permanence of depression changes at all. I'm trying to come up with an explanation for why this may be the case despite both predictors being significant on their own. We should talk with Jessica about this.

There are a lot of reasons we might get this result even if the reality of the situation is that people's beliefs _do_ act this way. We have a small sample and rudimentary/non-validated measures. Still, this isn't promising evidence. 

# Environment Regressions

```{r, results = "asis", echo = F}
model1 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_env_scaled)
model2 <- lm(data = df_2, yb_permanence_scaled ~ yb_change_env_scaled)
model3 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_env_scaled + yb_change_env_scaled) 
model4 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_env_scaled + yb_change_env_scaled + yb_cause_env_scaled*yb_change_env_scaled)
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_env_scaled + yb_change_env_scaled + yb_cause_env_scaled*yb_change_env_scaled + cdi_mean_scaled)

stargazer(model1, model2, model3, model4, model5, type = "html")

#plot_model(model5, type="pred", terms= "yb_cause_env_scaled")
#plot_model(model5, type="pred", terms= "yb_change_env_scaled")
interact_plot(model5, pred= yb_cause_env_scaled, modx= yb_change_env_scaled, plot.points= FALSE, interval = TRUE, main.title = "Env Interaction Controlling for CDI")
interact_plot(model4, pred= yb_cause_env_scaled, modx= yb_change_env_scaled, plot.points= FALSE, interval = TRUE, main.title = "Env Interaction Not Controlling for CDI")
```

Less to say about these, as even the basic relationships between `change_env` and `permanence` doesn't appear to hold.  The interaction is significant at the p=.1 level, but not when CDI is controlled for.

# Additional Visualizations
## Interactions

```{r, results = "asis", echo = F, fig.show="hold", out.width="50%"}
interaction.plot(x.factor=df_2$yb_cause_brain, trace.factor=df_2$yb_change_brain, response=df_2$yb_permanence,
                 xlab="Belief that depression is caused by brain", ylab="Belief that depression is permanent", 
                 trace.label="Brain malleability")

interaction.plot(x.factor=df_2$yb_cause_env, trace.factor=df_2$yb_change_env, response=df_2$yb_permanence,
                 xlab="Belief that depression is caused by env", ylab="Belief that depression is permanent", 
                 trace.label="Env malleability")

median_brain_malleability <- median(df_2$yb_change_brain)

median_env_malleability <- median(df_2$yb_change_env)

df_3 <- df_2 %>% mutate(malleability_brain = case_when(yb_change_brain <= median_brain_malleability ~ "low",
                                                       yb_change_brain > median_brain_malleability ~ "high"),
                        malleability_env = case_when(yb_change_env <= median_env_malleability ~ "low", 
                                                     yb_change_env > median_env_malleability ~ "high"))

interaction.plot(x.factor=df_3$yb_cause_brain, trace.factor=df_3$malleability_brain, response=df_3$yb_permanence,
                 xlab="Belief that depression is caused by brain", ylab="Belief that depression is permanent", 
                 trace.label="Brain malleability")

interaction.plot(x.factor=df_3$yb_cause_env, trace.factor=df_3$malleability_env, response=df_3$yb_permanence,
                 xlab="Belief that depression is caused by env", ylab="Belief that depression is permanent", 
                 trace.label="Env malleability")
```

The first two visualizations show how the relationship between teens' *beliefs that depression is caused by their brain/environment* and their *beliefs that depression is permanent* differs as a function of *how much they think their brain/environment can change to help depression get better* (1=least malleable; 5=most malleable).  The second two visualizations group teens' beliefs about brain/environment malleability into "high" and "low."  The high malleability group includes teens who gave a response above the median (i.e a score of 4 or 5) and the low malleability group includes teens who gave a response at or below the median (i.e. a score of 1, 2, or 3).

## Histograms

```{r, results = "asis", echo = F, fig.show="hold", out.width="50%"}
ggplot(df_3, aes(yb_permanence)) +  geom_histogram(aes(y=..density..), binwidth = 1) + ggtitle("Belief that Depression is Permanent") + 
  stat_function(fun=dnorm,args = list(mean = mean(df_3$yb_permanence), sd = sd(df_3$yb_permanence)), col="red")

ggplot(df_3, aes(yb_cause_brain)) +  geom_histogram(aes(y=..density..), binwidth = 1) + ggtitle("Belief that Depression is Caused by the Brain") + 
  stat_function(fun=dnorm,args = list(mean = mean(df_3$yb_cause_brain), sd = sd(df_3$yb_cause_brain)), col="red")

ggplot(df_3, aes(yb_cause_env)) +  geom_histogram(aes(y=..density..), binwidth = 1) + ggtitle("Belief that Depression is Caused by the Environment")+ 
  stat_function(fun=dnorm,args = list(mean = mean(df_3$yb_cause_env), sd = sd(df_3$yb_cause_env)), col="red")

ggplot(df_3, aes(yb_change_brain)) +  geom_histogram(aes(y=..density..), binwidth = 1) + ggtitle("Belief that Brain Can Change") + 
  stat_function(fun=dnorm,args = list(mean = mean(df_3$yb_change_brain), sd = sd(df_3$yb_change_brain)), col="red")

ggplot(df_3, aes(yb_change_env)) +  geom_histogram(aes(y=..density..), binwidth = 1) + ggtitle("Belief that Environment Can Change") + 
  stat_function(fun=dnorm,args = list(mean = mean(df_3$yb_change_env), sd = sd(df_3$yb_change_env)), col="red")
```

Histograms of each variable to see if the data are normally distributed.

# Checking Assumptions
## Multicollinearity
```{r, results = "asis", echo = F}
corr_matrix <- df_3 %>%
  select(yb_cause_brain, yb_change_brain, yb_cause_env, yb_change_env, cdi_mean) %>%
  cor()

#print(corr_matrix)
corrplot(corr_matrix, method = 'number')
```

In the above matrix, there is no correlation coefficient > 0.80, indicating that multicollinearity is not an issue.

## Linearity of Data
### Brain
```{r, results = "asis", echo = F}
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_brain_scaled + yb_change_brain_scaled + yb_cause_brain_scaled*yb_change_brain_scaled + cdi_mean_scaled)
plot(model5, 1)
```

### Environment
```{r, results = "asis", echo = F}
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_env_scaled + yb_change_env_scaled + yb_cause_env_scaled*yb_change_env_scaled + cdi_mean_scaled)
plot(model5, 1)
```

To meet the assumptions for an OLS regression, there should be a linear relationship between the predictor variables and outcome variables.  This would be indicated by a horizontal line approximately at zero.

## Predictors are Independent
### Durbin Watson Test

#### Brain
```{r, warning = F, echo = F}
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_brain_scaled + yb_change_brain_scaled + yb_cause_brain_scaled*yb_change_brain_scaled + cdi_mean_scaled)
durbinWatsonTest(model5)
```

#### Environment
```{r, warning = F, echo = F}
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_env_scaled + yb_change_env_scaled + yb_cause_env_scaled*yb_change_env_scaled + cdi_mean_scaled)
durbinWatsonTest(model5)
```
p-values > .05 indicate that predictors are independent of one another.  Our data appears to meat this assumption.

## Constant Variance of Residual Errors
### Brain
```{r, results = "asis", echo = F}
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_brain_scaled + yb_change_brain_scaled + yb_cause_brain_scaled*yb_change_brain_scaled + cdi_mean_scaled)
plot(model5, 3)
```

### Environment
```{r, results = "asis", echo = F}
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_env_scaled + yb_change_env_scaled + yb_cause_env_scaled*yb_change_env_scaled + cdi_mean_scaled)
plot(model5, 3)
```

### Breusch-Pagan Test
#### Brain
```{r, warning = F, echo = F}
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_brain_scaled + yb_change_brain_scaled + yb_cause_brain_scaled*yb_change_brain_scaled + cdi_mean_scaled)
ncvTest(model5)
```

#### Environment
```{r, warning = F, echo = F}
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_env_scaled + yb_change_env_scaled + yb_cause_env_scaled*yb_change_env_scaled + cdi_mean_scaled)
ncvTest(model5)
```
I double checked the homoscedasticity assumption using the Breusch-Pagan Test.  The null hypothesis is that the error variances are equal.  Our outcome of p < .05 (or close to it) indicates that our data may not meet this assumption.

## Normality of Residual Errors
### Q-Q Plot for Brain
```{r, results = "asis", echo = F}
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_brain_scaled + yb_change_brain_scaled + yb_cause_brain_scaled*yb_change_brain_scaled + cdi_mean_scaled)
ols_plot_resid_qq(model5)
```

### Q-Q Plot for Environment
```{r, results = "asis", echo = F}
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_env_scaled + yb_change_env_scaled + yb_cause_env_scaled*yb_change_env_scaled + cdi_mean_scaled)
ols_plot_resid_qq(model5)
```

### Shapiro-Wilk Test
### Brain
```{r, warning = F, echo = F}
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_brain_scaled + yb_change_brain_scaled + yb_cause_brain_scaled*yb_change_brain_scaled + cdi_mean_scaled)
ols_test_normality(model5)
```

### Environment
```{r, warning = F, echo = F}
model5 <- lm(data = df_2, yb_permanence_scaled ~ yb_cause_env_scaled + yb_change_env_scaled + yb_cause_env_scaled*yb_change_env_scaled + cdi_mean_scaled)
ols_test_normality(model5)
```

The Q-Q plots and outcomes of p > .05 (for the Shapiro-Wilk test) indicate that the residuals are normally distributed, meeting this OLS assumption.